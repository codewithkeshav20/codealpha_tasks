# Emotion Recognition From Speech ğŸ™ï¸ğŸ˜„ğŸ˜­ğŸ˜ 

This project focuses on recognizing human emotions from speech signals using machine learning and deep learning techniques. The model is trained on audio features extracted from speech datasets to classify emotions like happy, sad, angry, neutral, etc.

## ğŸš€ Features

- Extracts audio features like MFCCs, chroma, and mel spectrogram
- Uses machine learning (SVM, Random Forest) or deep learning (CNN, RNN) models
- Supports common datasets (e.g., RAVDESS, TESS, CREMA-D)
- Provides training and evaluation scripts
- Predicts emotion from a custom audio file

## ğŸ“ Dataset

This project supports datasets such as:

- [RAVDESS](https://zenodo.org/record/1188976)
- [TESS](https://tspace.library.utoronto.ca/handle/1807/24487)
- [CREMA-D](https://zenodo.org/record/1188976)

**Note**: Download the datasets separately and place them in a `data/` directory.

## ğŸ› ï¸ Installation

1. Clone the repo:

```bash
git clone https://github.com/yourusername/emotion-recognition-from-speech.git
cd emotion-recognition-from-speech
